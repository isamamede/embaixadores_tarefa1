#import os
from typing import List, Optional

import streamlit as st
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from pydantic import BaseModel

from tools import save_tool, search_tool

# ---------------------------
# API Key Input
# ---------------------------
# Load env
#oad_dotenv(dotenv_path=".\.env")

#OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

#print(OPENAI_API_KEY)

OPENAI_API_KEY="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"

if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY n√£o encontrada! Verifique seu arquivo .env")

# ---------------------------
# Tools
# ---------------------------
tools = [search_tool, save_tool]


# ---------------------------
# LLM
# ---------------------------
llm = ChatOpenAI(
    model="gpt-4o",
    openai_api_key=OPENAI_API_KEY,
    temperature=0.2,
)


# ---------------------------
# Data Model for Parsing
# ---------------------------
class ResearchResponse(BaseModel):
    topic: str
    answer: str
    sources: Optional[List[str]] = []
    tools_used: Optional[List[str]] = []


# ---------------------------
# Prompt Template with Parsing
# ---------------------------
parser = PydanticOutputParser(pydantic_object=ResearchResponse)

prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """
Voc√™ √© **Meta-Master**, um especialista em metodologia cient√≠fica, pesquisa acad√™mica, meta-an√°lises e escrita cient√≠fica.

Responda √†s perguntas utilizando as ferramentas necess√°rias. Seja did√°tico, claro, objetivo e use exemplos sempre que poss√≠vel.

Seu p√∫blico s√£o estudantes da √°rea da sa√∫de, com pouca familiaridade com pesquisa.

Formate sua resposta estritamente neste formato JSON e n√£o adicione nenhum texto extra:

{format_instructions}
""",
        ),
        ("human", "{query}"),
        ("placeholder", "{agent_scratchpad}"),
    ]
).partial(format_instructions=parser.get_format_instructions())


# ---------------------------
# Agent Setup
# ---------------------------
agent = create_tool_calling_agent(
    llm=llm,
    prompt=prompt,
    tools=tools,
)

agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=True,
)


# ---------------------------
# Session State (Only for Display)
# ---------------------------
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []


# ---------------------------
# Streamlit UI
# ---------------------------
st.title("ü§ñ Meta-Master ‚Äî AI Assistente de Pesquisa")
st.markdown(
    """
    Pergunte sobre metodologia cient√≠fica, revis√µes, escrita acad√™mica, cita√ß√µes, bancos de dados e muito mais.  
    Use ferramentas como busca na web e exporta√ß√£o para PDF.
    """
)


# Input de Pergunta
user_query = st.text_input("Digite sua pergunta:")

if user_query:
    with st.spinner("Meta-Master est√° pensando..."):
        try:
            inputs = {"query": user_query}

            raw_response = agent_executor.invoke(inputs)

            # Parse structured output
            structured_response = parser.parse(raw_response.get("output"))

            # Display structured response
            st.subheader("Resposta do Meta-Master:")
            st.markdown(f"**Tema:** {structured_response.topic}")
            st.markdown(f"**Resposta:** {structured_response.answer}")

            if structured_response.sources:
                st.markdown("**üîó Fontes:**")
                for src in structured_response.sources:
                    st.markdown(f"- {src}")

            if structured_response.tools_used:
                st.markdown("**üõ†Ô∏è Ferramentas usadas:**")
                for tool in structured_response.tools_used:
                    st.markdown(f"- {tool}")

            # üíæ Update chat history (for display only)
            st.session_state.chat_history.append(("Voc√™", user_query))
            st.session_state.chat_history.append(("Meta-Master", structured_response.answer))

        except Exception as e:
            st.error(f"‚ùå Erro na resposta: {e}")
            st.json(raw_response)


# ---------------------------
# Display Chat History (Only for UI)
# ---------------------------
if st.session_state.chat_history:
    with st.expander("üïë Hist√≥rico da Conversa"):
        for role, msg in st.session_state.chat_history:
            if role == "Voc√™":
                st.markdown(f"**üßë‚Äçüíª {role}:** {msg}")
            else:
                st.markdown(f"**ü§ñ {role}:** {msg}")
